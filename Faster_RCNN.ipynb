{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Faster_RCNN.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "nJQp5u9CvzBN"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "5b02cda8c88a4da885f599fb5603c338": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_fe7765f0f3bc48559690437dad8dc75c",
              "IPY_MODEL_8d4a7b8e6d434e07b7b3fcdc919f74ec",
              "IPY_MODEL_9a77339bbbc849bd86fdac798f1fb329"
            ],
            "layout": "IPY_MODEL_f0426fa0fa914f4c959034b508eb8a9a"
          }
        },
        "fe7765f0f3bc48559690437dad8dc75c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_82420bccbfeb4557ade0fdc4b6f67d5c",
            "placeholder": "​",
            "style": "IPY_MODEL_b790be1e05f1439cb1fa6cba0a273475",
            "value": "100%"
          }
        },
        "8d4a7b8e6d434e07b7b3fcdc919f74ec": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9e89d9560ef5490ca0acbf8b66245378",
            "max": 167502836,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_481f40a32a1f431985cccbc3e0a5b33a",
            "value": 167502836
          }
        },
        "9a77339bbbc849bd86fdac798f1fb329": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cf33576ca7ea47929cec272273a86d27",
            "placeholder": "​",
            "style": "IPY_MODEL_62718e4302544365a138d5357a617f75",
            "value": " 160M/160M [00:00&lt;00:00, 230MB/s]"
          }
        },
        "f0426fa0fa914f4c959034b508eb8a9a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "82420bccbfeb4557ade0fdc4b6f67d5c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b790be1e05f1439cb1fa6cba0a273475": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9e89d9560ef5490ca0acbf8b66245378": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "481f40a32a1f431985cccbc3e0a5b33a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "cf33576ca7ea47929cec272273a86d27": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "62718e4302544365a138d5357a617f75": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SzT0-yED9bxq"
      },
      "outputs": [],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchvision\n",
        "from PIL import Image\n",
        "import copy\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torchvision.transforms.functional as F\n",
        "import os"
      ],
      "metadata": {
        "id": "9JzJFov8_tSu"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(torch.cuda.get_device_properties(0))\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
      ],
      "metadata": {
        "id": "_kN6XQuUB6FH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "79130dcf-7863-41cb-d8c5-2ba23003c0db"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "_CudaDeviceProperties(name='Tesla T4', major=7, minor=5, total_memory=15109MB, multi_processor_count=40)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **LEVEL1- Use pretrained FasterRCNN model**"
      ],
      "metadata": {
        "id": "8GZlVncUNMK-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Open & display sample image*"
      ],
      "metadata": {
        "id": "MbeKlRHACt-0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "img_pil = Image.open(\"/content/obj-det-test.jpg\").convert(\"RGB\")\n",
        "display(img_pil)"
      ],
      "metadata": {
        "id": "xmu-eutuA2_s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Define pretrained FasterRcnn pytorch model*"
      ],
      "metadata": {
        "id": "lmdoFUIhDBa6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = torchvision.models.detection.fasterrcnn_resnet50_fpn(pretrained = True)\n",
        "model.to(device)"
      ],
      "metadata": {
        "id": "ToMLvlRaBsvJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Evaluation model*"
      ],
      "metadata": {
        "id": "YBC6xd6yEMV_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "img_tensor = F.to_tensor(img_pil)\n",
        "img_list   = [img_tensor.to(device)]\n",
        "\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    prediction = model(img_list)\n",
        "\n",
        "prediction"
      ],
      "metadata": {
        "id": "_fnSaIRMDz2C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "boxes  = prediction[0][\"boxes\"]\n",
        "labels = prediction[0][\"labels\"]\n",
        "scores = prediction[0][\"scores\"]"
      ],
      "metadata": {
        "id": "mk5cgwKkE9nn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from matplotlib.patches import Rectangle\n",
        "\n",
        "img_tensor_np = img_tensor.permute(1, 2, 0).cpu().numpy()\n",
        "plt.figure(figsize = (15, 15))\n",
        "plt.imshow(img_tensor_np)\n",
        "\n",
        "ax = plt.gca()\n",
        "for box, label, score in zip(boxes, labels, scores):\n",
        "    box = box.cpu().numpy()\n",
        "    score = score.cpu().numpy()\n",
        "    if score > 0.6:\n",
        "        rect = Rectangle((box[0],  box[1]),\n",
        "                        (box[2] - box[0]),\n",
        "                        (box[3] - box[1]),\n",
        "                        fill = False, edgecolor = (1, 0, 0), linewidth = 2)\n",
        "        ax.add_patch(rect)\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "P5q6I6bbFn9v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Train* pytorch pretrain FasterRCNN "
      ],
      "metadata": {
        "id": "ECnmrlYdL_h0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "targets = []\n",
        "target  = {}\n",
        "target[\"boxes\"]  = boxes\n",
        "target[\"labels\"] = labels\n",
        "targets.append(target)\n",
        "\n",
        "model.train()\n",
        "loss = model(img_list, targets)\n",
        "loss"
      ],
      "metadata": {
        "id": "OqSuERE4L7DI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **LEVEL2- Use pytorch FasterRCNN model in raccoon dataset**"
      ],
      "metadata": {
        "id": "x9hKp1D6OHmr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/experiencor/raccoon_dataset"
      ],
      "metadata": {
        "id": "_2aKOTrbOf3C",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e02db0d6-e4e9-46f6-b926-55216a4460f4"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'raccoon_dataset'...\n",
            "remote: Enumerating objects: 646, done.\u001b[K\n",
            "remote: Total 646 (delta 0), reused 0 (delta 0), pack-reused 646\u001b[K\n",
            "Receiving objects: 100% (646/646), 48.00 MiB | 17.71 MiB/s, done.\n",
            "Resolving deltas: 100% (412/412), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "root  = \"/content/raccoon_dataset\"\n",
        "phase = \"train\"\n",
        "\n",
        "images  = os.listdir(os.path.join(root, \"images\"))\n",
        "targets = pd.read_csv(os.path.join(root, \"data/{}_labels.csv\".format(phase)))\n",
        "\n",
        "idx = \"raccoon-119.jpg\"\n",
        "img_path = os.path.join(root, \"images/{}\".format(idx))\n",
        "img = Image.open(img_path).convert(\"RGB\")\n",
        "display(img)\n",
        "\n",
        "box_list = targets[targets[\"filename\"] == \"raccoon-119.jpg\"]\n",
        "box_list = box_list[[\"xmin\", \"ymin\", \"xmax\", \"ymax\"]].values\n",
        "print(box_list)"
      ],
      "metadata": {
        "id": "ENPYWYUC0xL6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*plot one random sample from dataset*"
      ],
      "metadata": {
        "id": "sgfGHrM58bEu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from matplotlib.patches import Rectangle\n",
        "\n",
        "img_tensor = F.to_tensor(img).permute(1, 2, 0).cpu().numpy()\n",
        "\n",
        "plt.figure(figsize = (12,12))\n",
        "plt.imshow(img_tensor)\n",
        "\n",
        "ax = plt.gca()\n",
        "for l in box_list:\n",
        "    rect = Rectangle((l[0],  l[1]),\n",
        "                     (l[2] - l[0]),\n",
        "                     (l[3] - l[1]),\n",
        "                     fill = False, edgecolor = (1, 0, 0), linewidth = 2)\n",
        "    ax.add_patch(rect)\n",
        "\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "JPl8z5Zx59nw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Costum dataset**"
      ],
      "metadata": {
        "id": "h3PJwUR2KAXC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class RaccoonDataset(torch.utils.data.Dataset):\n",
        "\n",
        "    def __init__(self, root, phase):\n",
        "        self.root  = root\n",
        "        self.phase = phase\n",
        "\n",
        "        #self.images_name = os.listdir(os.path.join(self.root, \"images\"))\n",
        "        self.targets     = pd.read_csv(os.path.join(self.root, \"data/{}_labels.csv\".format(self.phase)))\n",
        "        self.images_name = self.targets[\"filename\"]\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        # images\n",
        "        img_path   = os.path.join(self.root, \"images\", self.images_name[idx])\n",
        "        img        = Image.open(img_path).convert(\"RGB\")\n",
        "        img_tensor = F.to_tensor(img)\n",
        "\n",
        "        # boxes\n",
        "        target     = self.targets[self.targets[\"filename\"] == self.images_name[idx]]\n",
        "        boxes_list = target[[\"xmin\", \"ymin\", \"xmax\", \"ymax\"]].values   # boxes is a numpy array\n",
        "        boxes      = torch.tensor(boxes_list, dtype = torch.float32)\n",
        "\n",
        "        # labels\n",
        "        labels     = torch.ones((len(boxes_list), ), dtype = torch.int64)\n",
        "\n",
        "        #rac_targets = []\n",
        "        rac_target  = {}\n",
        "        rac_target[\"boxes\"]  = boxes\n",
        "        rac_target[\"labels\"] = labels\n",
        "        #rac_targets.append(rac_target)\n",
        "\n",
        "        return img_tensor, rac_target\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.images_name)\n"
      ],
      "metadata": {
        "id": "2l21MLoS4LFM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainset = RaccoonDataset(root = \"/content/raccoon_dataset\", phase = \"train\")\n",
        "testset  = RaccoonDataset(root = \"/content/raccoon_dataset\", phase = \"test\")"
      ],
      "metadata": {
        "id": "utUQ3mFvKK52"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainset.__getitem__(10)"
      ],
      "metadata": {
        "id": "IY--KGCAKqaZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d3e25ea7-26f2-4bef-c0a2-172473d9ce8e"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[[0.7294, 0.7294, 0.7255,  ..., 0.4431, 0.4353, 0.4235],\n",
              "          [0.7294, 0.7294, 0.7255,  ..., 0.4353, 0.4314, 0.4431],\n",
              "          [0.7294, 0.7294, 0.7255,  ..., 0.4863, 0.4824, 0.4784],\n",
              "          ...,\n",
              "          [0.2980, 0.3333, 0.4314,  ..., 0.4353, 0.4588, 0.4588],\n",
              "          [0.3490, 0.3412, 0.3294,  ..., 0.4118, 0.4275, 0.4235],\n",
              "          [0.3569, 0.3412, 0.3686,  ..., 0.4157, 0.4275, 0.4275]],\n",
              " \n",
              "         [[0.6314, 0.6314, 0.6314,  ..., 0.3529, 0.3412, 0.3294],\n",
              "          [0.6314, 0.6314, 0.6314,  ..., 0.3412, 0.3373, 0.3490],\n",
              "          [0.6314, 0.6314, 0.6314,  ..., 0.3922, 0.3882, 0.3843],\n",
              "          ...,\n",
              "          [0.2706, 0.3059, 0.4039,  ..., 0.3098, 0.3333, 0.3333],\n",
              "          [0.3216, 0.3137, 0.3020,  ..., 0.2863, 0.3020, 0.2980],\n",
              "          [0.3216, 0.3059, 0.3333,  ..., 0.2902, 0.3020, 0.3020]],\n",
              " \n",
              "         [[0.4745, 0.4745, 0.4588,  ..., 0.2980, 0.2941, 0.2824],\n",
              "          [0.4745, 0.4706, 0.4588,  ..., 0.2941, 0.2902, 0.3020],\n",
              "          [0.4706, 0.4706, 0.4588,  ..., 0.3451, 0.3412, 0.3373],\n",
              "          ...,\n",
              "          [0.2471, 0.2824, 0.3804,  ..., 0.1608, 0.1843, 0.1843],\n",
              "          [0.2980, 0.2902, 0.2784,  ..., 0.1373, 0.1529, 0.1490],\n",
              "          [0.2941, 0.2784, 0.3059,  ..., 0.1412, 0.1529, 0.1529]]]),\n",
              " {'boxes': tensor([[ 31.,   6., 197., 163.]]), 'labels': tensor([1])})"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def new_concat(batch):\n",
        "    return tuple(zip(*batch))"
      ],
      "metadata": {
        "id": "Ct0yM7FvNWDy"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size = 2, \n",
        "                                          shuffle = True, num_workers = 2, collate_fn = new_concat)\n",
        "testloader  = torch.utils.data.DataLoader(testset,  batch_size = 1,\n",
        "                                          shuffle = True, num_workers = 2, collate_fn = new_concat)"
      ],
      "metadata": {
        "id": "GPTpZiY6KvEL"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch = next(iter(trainloader))\n",
        "batch"
      ],
      "metadata": {
        "id": "b_0R1rAbLxzY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c8d86f84-b1bc-468f-95d6-8b62a5d02d79"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((tensor([[[0.4588, 0.4745, 0.4902,  ..., 0.5961, 0.6157, 0.6314],\n",
              "           [0.4745, 0.4824, 0.4863,  ..., 0.5333, 0.5647, 0.6000],\n",
              "           [0.4863, 0.4863, 0.4824,  ..., 0.5137, 0.5412, 0.5765],\n",
              "           ...,\n",
              "           [0.2667, 0.2745, 0.2863,  ..., 0.3137, 0.3176, 0.3529],\n",
              "           [0.2784, 0.2863, 0.2941,  ..., 0.3255, 0.3294, 0.3373],\n",
              "           [0.2784, 0.2863, 0.2941,  ..., 0.3255, 0.3294, 0.3373]],\n",
              "  \n",
              "          [[0.6588, 0.6745, 0.6824,  ..., 0.6863, 0.7020, 0.7176],\n",
              "           [0.6667, 0.6745, 0.6784,  ..., 0.6275, 0.6549, 0.6902],\n",
              "           [0.6824, 0.6784, 0.6745,  ..., 0.6039, 0.6314, 0.6667],\n",
              "           ...,\n",
              "           [0.3490, 0.3569, 0.3686,  ..., 0.1804, 0.1725, 0.2078],\n",
              "           [0.3490, 0.3569, 0.3647,  ..., 0.1922, 0.1961, 0.2039],\n",
              "           [0.3490, 0.3569, 0.3647,  ..., 0.1922, 0.1961, 0.2039]],\n",
              "  \n",
              "          [[0.1529, 0.1686, 0.1804,  ..., 0.5216, 0.5490, 0.5686],\n",
              "           [0.1647, 0.1725, 0.1765,  ..., 0.4392, 0.4745, 0.5176],\n",
              "           [0.1686, 0.1765, 0.1725,  ..., 0.3922, 0.4196, 0.4549],\n",
              "           ...,\n",
              "           [0.1882, 0.1961, 0.2078,  ..., 0.1451, 0.1412, 0.1725],\n",
              "           [0.1843, 0.1922, 0.2000,  ..., 0.1529, 0.1569, 0.1647],\n",
              "           [0.1843, 0.1922, 0.2000,  ..., 0.1529, 0.1569, 0.1647]]]),\n",
              "  tensor([[[0.1529, 0.1412, 0.1333,  ..., 0.4078, 0.4157, 0.4431],\n",
              "           [0.1412, 0.1333, 0.1216,  ..., 0.4392, 0.4196, 0.4235],\n",
              "           [0.1294, 0.1333, 0.1294,  ..., 0.4471, 0.4275, 0.4118],\n",
              "           ...,\n",
              "           [0.5059, 0.5216, 0.5451,  ..., 0.5412, 0.5490, 0.5490],\n",
              "           [0.5569, 0.5804, 0.6078,  ..., 0.5333, 0.5373, 0.5451],\n",
              "           [0.5686, 0.5922, 0.6118,  ..., 0.5216, 0.5216, 0.5333]],\n",
              "  \n",
              "          [[0.1059, 0.1059, 0.1137,  ..., 0.4784, 0.4902, 0.5176],\n",
              "           [0.1059, 0.1059, 0.1059,  ..., 0.5020, 0.4941, 0.4980],\n",
              "           [0.1098, 0.1176, 0.1294,  ..., 0.5137, 0.4941, 0.4784],\n",
              "           ...,\n",
              "           [0.4902, 0.5020, 0.5333,  ..., 0.5255, 0.5333, 0.5333],\n",
              "           [0.5412, 0.5608, 0.5882,  ..., 0.5176, 0.5333, 0.5412],\n",
              "           [0.5529, 0.5725, 0.5922,  ..., 0.5059, 0.5176, 0.5294]],\n",
              "  \n",
              "          [[0.1216, 0.1255, 0.1412,  ..., 0.4784, 0.4824, 0.5098],\n",
              "           [0.1255, 0.1373, 0.1608,  ..., 0.4980, 0.4863, 0.4824],\n",
              "           [0.1333, 0.1725, 0.2235,  ..., 0.4902, 0.4706, 0.4549],\n",
              "           ...,\n",
              "           [0.4549, 0.4784, 0.5137,  ..., 0.5294, 0.5373, 0.5373],\n",
              "           [0.5059, 0.5373, 0.5725,  ..., 0.5137, 0.5255, 0.5333],\n",
              "           [0.5176, 0.5490, 0.5765,  ..., 0.5020, 0.5098, 0.5216]]])),\n",
              " ({'boxes': tensor([[  4.,  54., 574., 410.]]), 'labels': tensor([1])},\n",
              "  {'boxes': tensor([[ 44.,  90., 577., 426.]]), 'labels': tensor([1])}))"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Define model"
      ],
      "metadata": {
        "id": "DARCoGkRSeXr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = torchvision.models.detection.fasterrcnn_resnet50_fpn(pretrained = True)\n",
        "model.roi_heads.box_predictor = torchvision.models.detection.faster_rcnn.FastRCNNPredictor(1024, 2)\n",
        "model.to(device)\n",
        "model"
      ],
      "metadata": {
        "id": "mwd_95m_L-0z",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "5b02cda8c88a4da885f599fb5603c338",
            "fe7765f0f3bc48559690437dad8dc75c",
            "8d4a7b8e6d434e07b7b3fcdc919f74ec",
            "9a77339bbbc849bd86fdac798f1fb329",
            "f0426fa0fa914f4c959034b508eb8a9a",
            "82420bccbfeb4557ade0fdc4b6f67d5c",
            "b790be1e05f1439cb1fa6cba0a273475",
            "9e89d9560ef5490ca0acbf8b66245378",
            "481f40a32a1f431985cccbc3e0a5b33a",
            "cf33576ca7ea47929cec272273a86d27",
            "62718e4302544365a138d5357a617f75"
          ]
        },
        "outputId": "688864f0-b5eb-457b-d109-38969619ec5c"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torchvision/models/_utils.py:209: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and will be removed in 0.15, please use 'weights' instead.\n",
            "  f\"The parameter '{pretrained_param}' is deprecated since 0.13 and will be removed in 0.15, \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=FasterRCNN_ResNet50_FPN_Weights.COCO_V1`. You can also use `weights=FasterRCNN_ResNet50_FPN_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/fasterrcnn_resnet50_fpn_coco-258fb6c6.pth\" to /root/.cache/torch/hub/checkpoints/fasterrcnn_resnet50_fpn_coco-258fb6c6.pth\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0.00/160M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5b02cda8c88a4da885f599fb5603c338"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "FasterRCNN(\n",
              "  (transform): GeneralizedRCNNTransform(\n",
              "      Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
              "      Resize(min_size=(800,), max_size=1333, mode='bilinear')\n",
              "  )\n",
              "  (backbone): BackboneWithFPN(\n",
              "    (body): IntermediateLayerGetter(\n",
              "      (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
              "      (bn1): FrozenBatchNorm2d(64, eps=0.0)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
              "      (layer1): Sequential(\n",
              "        (0): Bottleneck(\n",
              "          (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): FrozenBatchNorm2d(64, eps=0.0)\n",
              "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): FrozenBatchNorm2d(64, eps=0.0)\n",
              "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): FrozenBatchNorm2d(256, eps=0.0)\n",
              "          (relu): ReLU(inplace=True)\n",
              "          (downsample): Sequential(\n",
              "            (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): FrozenBatchNorm2d(256, eps=0.0)\n",
              "          )\n",
              "        )\n",
              "        (1): Bottleneck(\n",
              "          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): FrozenBatchNorm2d(64, eps=0.0)\n",
              "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): FrozenBatchNorm2d(64, eps=0.0)\n",
              "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): FrozenBatchNorm2d(256, eps=0.0)\n",
              "          (relu): ReLU(inplace=True)\n",
              "        )\n",
              "        (2): Bottleneck(\n",
              "          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): FrozenBatchNorm2d(64, eps=0.0)\n",
              "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): FrozenBatchNorm2d(64, eps=0.0)\n",
              "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): FrozenBatchNorm2d(256, eps=0.0)\n",
              "          (relu): ReLU(inplace=True)\n",
              "        )\n",
              "      )\n",
              "      (layer2): Sequential(\n",
              "        (0): Bottleneck(\n",
              "          (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): FrozenBatchNorm2d(128, eps=0.0)\n",
              "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "          (bn2): FrozenBatchNorm2d(128, eps=0.0)\n",
              "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): FrozenBatchNorm2d(512, eps=0.0)\n",
              "          (relu): ReLU(inplace=True)\n",
              "          (downsample): Sequential(\n",
              "            (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "            (1): FrozenBatchNorm2d(512, eps=0.0)\n",
              "          )\n",
              "        )\n",
              "        (1): Bottleneck(\n",
              "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): FrozenBatchNorm2d(128, eps=0.0)\n",
              "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): FrozenBatchNorm2d(128, eps=0.0)\n",
              "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): FrozenBatchNorm2d(512, eps=0.0)\n",
              "          (relu): ReLU(inplace=True)\n",
              "        )\n",
              "        (2): Bottleneck(\n",
              "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): FrozenBatchNorm2d(128, eps=0.0)\n",
              "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): FrozenBatchNorm2d(128, eps=0.0)\n",
              "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): FrozenBatchNorm2d(512, eps=0.0)\n",
              "          (relu): ReLU(inplace=True)\n",
              "        )\n",
              "        (3): Bottleneck(\n",
              "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): FrozenBatchNorm2d(128, eps=0.0)\n",
              "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): FrozenBatchNorm2d(128, eps=0.0)\n",
              "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): FrozenBatchNorm2d(512, eps=0.0)\n",
              "          (relu): ReLU(inplace=True)\n",
              "        )\n",
              "      )\n",
              "      (layer3): Sequential(\n",
              "        (0): Bottleneck(\n",
              "          (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): FrozenBatchNorm2d(256, eps=0.0)\n",
              "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "          (bn2): FrozenBatchNorm2d(256, eps=0.0)\n",
              "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): FrozenBatchNorm2d(1024, eps=0.0)\n",
              "          (relu): ReLU(inplace=True)\n",
              "          (downsample): Sequential(\n",
              "            (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "            (1): FrozenBatchNorm2d(1024, eps=0.0)\n",
              "          )\n",
              "        )\n",
              "        (1): Bottleneck(\n",
              "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): FrozenBatchNorm2d(256, eps=0.0)\n",
              "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): FrozenBatchNorm2d(256, eps=0.0)\n",
              "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): FrozenBatchNorm2d(1024, eps=0.0)\n",
              "          (relu): ReLU(inplace=True)\n",
              "        )\n",
              "        (2): Bottleneck(\n",
              "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): FrozenBatchNorm2d(256, eps=0.0)\n",
              "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): FrozenBatchNorm2d(256, eps=0.0)\n",
              "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): FrozenBatchNorm2d(1024, eps=0.0)\n",
              "          (relu): ReLU(inplace=True)\n",
              "        )\n",
              "        (3): Bottleneck(\n",
              "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): FrozenBatchNorm2d(256, eps=0.0)\n",
              "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): FrozenBatchNorm2d(256, eps=0.0)\n",
              "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): FrozenBatchNorm2d(1024, eps=0.0)\n",
              "          (relu): ReLU(inplace=True)\n",
              "        )\n",
              "        (4): Bottleneck(\n",
              "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): FrozenBatchNorm2d(256, eps=0.0)\n",
              "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): FrozenBatchNorm2d(256, eps=0.0)\n",
              "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): FrozenBatchNorm2d(1024, eps=0.0)\n",
              "          (relu): ReLU(inplace=True)\n",
              "        )\n",
              "        (5): Bottleneck(\n",
              "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): FrozenBatchNorm2d(256, eps=0.0)\n",
              "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): FrozenBatchNorm2d(256, eps=0.0)\n",
              "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): FrozenBatchNorm2d(1024, eps=0.0)\n",
              "          (relu): ReLU(inplace=True)\n",
              "        )\n",
              "      )\n",
              "      (layer4): Sequential(\n",
              "        (0): Bottleneck(\n",
              "          (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): FrozenBatchNorm2d(512, eps=0.0)\n",
              "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "          (bn2): FrozenBatchNorm2d(512, eps=0.0)\n",
              "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): FrozenBatchNorm2d(2048, eps=0.0)\n",
              "          (relu): ReLU(inplace=True)\n",
              "          (downsample): Sequential(\n",
              "            (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "            (1): FrozenBatchNorm2d(2048, eps=0.0)\n",
              "          )\n",
              "        )\n",
              "        (1): Bottleneck(\n",
              "          (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): FrozenBatchNorm2d(512, eps=0.0)\n",
              "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): FrozenBatchNorm2d(512, eps=0.0)\n",
              "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): FrozenBatchNorm2d(2048, eps=0.0)\n",
              "          (relu): ReLU(inplace=True)\n",
              "        )\n",
              "        (2): Bottleneck(\n",
              "          (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): FrozenBatchNorm2d(512, eps=0.0)\n",
              "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): FrozenBatchNorm2d(512, eps=0.0)\n",
              "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): FrozenBatchNorm2d(2048, eps=0.0)\n",
              "          (relu): ReLU(inplace=True)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (fpn): FeaturePyramidNetwork(\n",
              "      (inner_blocks): ModuleList(\n",
              "        (0): Conv2dNormActivation(\n",
              "          (0): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
              "        )\n",
              "        (1): Conv2dNormActivation(\n",
              "          (0): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
              "        )\n",
              "        (2): Conv2dNormActivation(\n",
              "          (0): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
              "        )\n",
              "        (3): Conv2dNormActivation(\n",
              "          (0): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
              "        )\n",
              "      )\n",
              "      (layer_blocks): ModuleList(\n",
              "        (0): Conv2dNormActivation(\n",
              "          (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        )\n",
              "        (1): Conv2dNormActivation(\n",
              "          (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        )\n",
              "        (2): Conv2dNormActivation(\n",
              "          (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        )\n",
              "        (3): Conv2dNormActivation(\n",
              "          (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        )\n",
              "      )\n",
              "      (extra_blocks): LastLevelMaxPool()\n",
              "    )\n",
              "  )\n",
              "  (rpn): RegionProposalNetwork(\n",
              "    (anchor_generator): AnchorGenerator()\n",
              "    (head): RPNHead(\n",
              "      (conv): Sequential(\n",
              "        (0): Conv2dNormActivation(\n",
              "          (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "          (1): ReLU(inplace=True)\n",
              "        )\n",
              "      )\n",
              "      (cls_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (bbox_pred): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n",
              "    )\n",
              "  )\n",
              "  (roi_heads): RoIHeads(\n",
              "    (box_roi_pool): MultiScaleRoIAlign(featmap_names=['0', '1', '2', '3'], output_size=(7, 7), sampling_ratio=2)\n",
              "    (box_head): TwoMLPHead(\n",
              "      (fc6): Linear(in_features=12544, out_features=1024, bias=True)\n",
              "      (fc7): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "    )\n",
              "    (box_predictor): FastRCNNPredictor(\n",
              "      (cls_score): Linear(in_features=1024, out_features=2, bias=True)\n",
              "      (bbox_pred): Linear(in_features=1024, out_features=8, bias=True)\n",
              "    )\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## model config"
      ],
      "metadata": {
        "id": "WGu5LVA8Uicj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = torch.optim.Adam(params = model.parameters(), lr = 0.0002, weight_decay = 1e-5)\n",
        "\n",
        "lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer = optimizer, step_size = 3, gamma = 0.5)"
      ],
      "metadata": {
        "id": "UBc66J2fMhFE"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_one_epoch(model, optimizer, train_loader):\n",
        "    model.train()\n",
        "    loss_total = 0\n",
        "    for images, targets in train_loader:\n",
        "        optimizer.zero_grad()\n",
        "        images      = [img.to(device) for img in images]\n",
        "        targets     = [{k: v.to(device) for k, v in t.items()} for t in targets]\n",
        "        loss_dict   = model(images, targets)\n",
        "        loss        = sum(loss for loss in loss_dict.values())\n",
        "        loss_total += loss\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "\n",
        "    return loss_total / len(train_loader)\n"
      ],
      "metadata": {
        "id": "M_pER12rT5Yc"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install termcolor2\n",
        "from termcolor2 import colored "
      ],
      "metadata": {
        "id": "CiZ737GkaZhJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "76fa785c-021c-4594-d766-68bdc7424904"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting termcolor2\n",
            "  Downloading termcolor2-0.0.3.tar.gz (1.6 kB)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.7/dist-packages (from termcolor2) (1.1.0)\n",
            "Building wheels for collected packages: termcolor2\n",
            "  Building wheel for termcolor2 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for termcolor2: filename=termcolor2-0.0.3-py3-none-any.whl size=1833 sha256=905ef6e5f9dd55711ca6b7b5496e8c8a57863f68d6170cccc053d66c0c695f01\n",
            "  Stored in directory: /root/.cache/pip/wheels/37/93/fa/3ead517c143d4381f9b4096524f21b1d86a5fa60d08210abe8\n",
            "Successfully built termcolor2\n",
            "Installing collected packages: termcolor2\n",
            "Successfully installed termcolor2-0.0.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import datetime\n",
        "train_epochs = 50\n",
        "\n",
        "for epoch in range(train_epochs):\n",
        "    s_time = datetime.datetime.now()\n",
        "    loss   = train_one_epoch(model, optimizer, trainloader)\n",
        "    e_time = datetime.datetime.now()\n",
        "    train_time = str(e_time - s_time)\n",
        "    print(colored(\"Epoch: [{}] \\t \".format(epoch + 1)),\n",
        "          colored(f\"Time: {train_time} \\t \", color = \"blue\"),\n",
        "          colored(\"Loss: {0:.4} \\t \".format(loss), color = \"red\"),\n",
        "          colored(\"LR: {}  \".format(lr_scheduler.get_last_lr()), color = \"green\")) \n",
        "\n",
        "\n",
        "    lr_scheduler.step()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MXrPP4KmZySJ",
        "outputId": "93dcd256-b0da-47f5-e056-8a7ec91eeaad"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: [1] \t \u001b[0m \u001b[34mTime: 0:00:53.622446 \t \u001b[0m \u001b[31mLoss: 0.2422 \t \u001b[0m \u001b[32mLR: [0.0002]  \u001b[0m\n",
            "Epoch: [2] \t \u001b[0m \u001b[34mTime: 0:00:51.092353 \t \u001b[0m \u001b[31mLoss: 0.2344 \t \u001b[0m \u001b[32mLR: [0.0002]  \u001b[0m\n",
            "Epoch: [3] \t \u001b[0m \u001b[34mTime: 0:00:50.798165 \t \u001b[0m \u001b[31mLoss: 0.2385 \t \u001b[0m \u001b[32mLR: [0.0002]  \u001b[0m\n",
            "Epoch: [4] \t \u001b[0m \u001b[34mTime: 0:00:51.544479 \t \u001b[0m \u001b[31mLoss: 0.2094 \t \u001b[0m \u001b[32mLR: [0.0001]  \u001b[0m\n",
            "Epoch: [5] \t \u001b[0m \u001b[34mTime: 0:00:52.077975 \t \u001b[0m \u001b[31mLoss: 0.1864 \t \u001b[0m \u001b[32mLR: [0.0001]  \u001b[0m\n",
            "Epoch: [6] \t \u001b[0m \u001b[34mTime: 0:00:51.557349 \t \u001b[0m \u001b[31mLoss: 0.1744 \t \u001b[0m \u001b[32mLR: [0.0001]  \u001b[0m\n",
            "Epoch: [7] \t \u001b[0m \u001b[34mTime: 0:00:51.622532 \t \u001b[0m \u001b[31mLoss: 0.1563 \t \u001b[0m \u001b[32mLR: [5e-05]  \u001b[0m\n",
            "Epoch: [8] \t \u001b[0m \u001b[34mTime: 0:00:51.186432 \t \u001b[0m \u001b[31mLoss: 0.1444 \t \u001b[0m \u001b[32mLR: [5e-05]  \u001b[0m\n",
            "Epoch: [9] \t \u001b[0m \u001b[34mTime: 0:00:51.496776 \t \u001b[0m \u001b[31mLoss: 0.1315 \t \u001b[0m \u001b[32mLR: [5e-05]  \u001b[0m\n",
            "Epoch: [10] \t \u001b[0m \u001b[34mTime: 0:00:51.521102 \t \u001b[0m \u001b[31mLoss: 0.1201 \t \u001b[0m \u001b[32mLR: [2.5e-05]  \u001b[0m\n",
            "Epoch: [11] \t \u001b[0m \u001b[34mTime: 0:00:51.153247 \t \u001b[0m \u001b[31mLoss: 0.119 \t \u001b[0m \u001b[32mLR: [2.5e-05]  \u001b[0m\n",
            "Epoch: [12] \t \u001b[0m \u001b[34mTime: 0:00:51.186889 \t \u001b[0m \u001b[31mLoss: 0.108 \t \u001b[0m \u001b[32mLR: [2.5e-05]  \u001b[0m\n",
            "Epoch: [13] \t \u001b[0m \u001b[34mTime: 0:00:51.914190 \t \u001b[0m \u001b[31mLoss: 0.1027 \t \u001b[0m \u001b[32mLR: [1.25e-05]  \u001b[0m\n",
            "Epoch: [14] \t \u001b[0m \u001b[34mTime: 0:00:52.143835 \t \u001b[0m \u001b[31mLoss: 0.09961 \t \u001b[0m \u001b[32mLR: [1.25e-05]  \u001b[0m\n",
            "Epoch: [15] \t \u001b[0m \u001b[34mTime: 0:00:51.610739 \t \u001b[0m \u001b[31mLoss: 0.09574 \t \u001b[0m \u001b[32mLR: [1.25e-05]  \u001b[0m\n",
            "Epoch: [16] \t \u001b[0m \u001b[34mTime: 0:00:51.363138 \t \u001b[0m \u001b[31mLoss: 0.08765 \t \u001b[0m \u001b[32mLR: [6.25e-06]  \u001b[0m\n",
            "Epoch: [17] \t \u001b[0m \u001b[34mTime: 0:00:51.822717 \t \u001b[0m \u001b[31mLoss: 0.08559 \t \u001b[0m \u001b[32mLR: [6.25e-06]  \u001b[0m\n",
            "Epoch: [18] \t \u001b[0m \u001b[34mTime: 0:00:50.708690 \t \u001b[0m \u001b[31mLoss: 0.0833 \t \u001b[0m \u001b[32mLR: [6.25e-06]  \u001b[0m\n",
            "Epoch: [19] \t \u001b[0m \u001b[34mTime: 0:00:51.643517 \t \u001b[0m \u001b[31mLoss: 0.08097 \t \u001b[0m \u001b[32mLR: [3.125e-06]  \u001b[0m\n",
            "Epoch: [20] \t \u001b[0m \u001b[34mTime: 0:00:51.316994 \t \u001b[0m \u001b[31mLoss: 0.08043 \t \u001b[0m \u001b[32mLR: [3.125e-06]  \u001b[0m\n",
            "Epoch: [21] \t \u001b[0m \u001b[34mTime: 0:00:51.299277 \t \u001b[0m \u001b[31mLoss: 0.07607 \t \u001b[0m \u001b[32mLR: [3.125e-06]  \u001b[0m\n",
            "Epoch: [22] \t \u001b[0m \u001b[34mTime: 0:00:51.708421 \t \u001b[0m \u001b[31mLoss: 0.07509 \t \u001b[0m \u001b[32mLR: [1.5625e-06]  \u001b[0m\n",
            "Epoch: [23] \t \u001b[0m \u001b[34mTime: 0:00:51.835045 \t \u001b[0m \u001b[31mLoss: 0.07411 \t \u001b[0m \u001b[32mLR: [1.5625e-06]  \u001b[0m\n",
            "Epoch: [24] \t \u001b[0m \u001b[34mTime: 0:00:51.689406 \t \u001b[0m \u001b[31mLoss: 0.07417 \t \u001b[0m \u001b[32mLR: [1.5625e-06]  \u001b[0m\n",
            "Epoch: [25] \t \u001b[0m \u001b[34mTime: 0:00:51.976891 \t \u001b[0m \u001b[31mLoss: 0.07221 \t \u001b[0m \u001b[32mLR: [7.8125e-07]  \u001b[0m\n",
            "Epoch: [26] \t \u001b[0m \u001b[34mTime: 0:00:51.672641 \t \u001b[0m \u001b[31mLoss: 0.07355 \t \u001b[0m \u001b[32mLR: [7.8125e-07]  \u001b[0m\n",
            "Epoch: [27] \t \u001b[0m \u001b[34mTime: 0:00:51.405035 \t \u001b[0m \u001b[31mLoss: 0.0723 \t \u001b[0m \u001b[32mLR: [7.8125e-07]  \u001b[0m\n",
            "Epoch: [28] \t \u001b[0m \u001b[34mTime: 0:00:52.468677 \t \u001b[0m \u001b[31mLoss: 0.072 \t \u001b[0m \u001b[32mLR: [3.90625e-07]  \u001b[0m\n",
            "Epoch: [29] \t \u001b[0m \u001b[34mTime: 0:00:52.032766 \t \u001b[0m \u001b[31mLoss: 0.07129 \t \u001b[0m \u001b[32mLR: [3.90625e-07]  \u001b[0m\n",
            "Epoch: [30] \t \u001b[0m \u001b[34mTime: 0:00:51.326903 \t \u001b[0m \u001b[31mLoss: 0.0714 \t \u001b[0m \u001b[32mLR: [3.90625e-07]  \u001b[0m\n",
            "Epoch: [31] \t \u001b[0m \u001b[34mTime: 0:00:51.690703 \t \u001b[0m \u001b[31mLoss: 0.07167 \t \u001b[0m \u001b[32mLR: [1.953125e-07]  \u001b[0m\n",
            "Epoch: [32] \t \u001b[0m \u001b[34mTime: 0:00:51.545667 \t \u001b[0m \u001b[31mLoss: 0.07044 \t \u001b[0m \u001b[32mLR: [1.953125e-07]  \u001b[0m\n",
            "Epoch: [33] \t \u001b[0m \u001b[34mTime: 0:00:51.712050 \t \u001b[0m \u001b[31mLoss: 0.07057 \t \u001b[0m \u001b[32mLR: [1.953125e-07]  \u001b[0m\n",
            "Epoch: [34] \t \u001b[0m \u001b[34mTime: 0:00:51.323194 \t \u001b[0m \u001b[31mLoss: 0.07077 \t \u001b[0m \u001b[32mLR: [9.765625e-08]  \u001b[0m\n",
            "Epoch: [35] \t \u001b[0m \u001b[34mTime: 0:00:50.865618 \t \u001b[0m \u001b[31mLoss: 0.07006 \t \u001b[0m \u001b[32mLR: [9.765625e-08]  \u001b[0m\n",
            "Epoch: [36] \t \u001b[0m \u001b[34mTime: 0:00:51.948443 \t \u001b[0m \u001b[31mLoss: 0.07066 \t \u001b[0m \u001b[32mLR: [9.765625e-08]  \u001b[0m\n",
            "Epoch: [37] \t \u001b[0m \u001b[34mTime: 0:00:52.179130 \t \u001b[0m \u001b[31mLoss: 0.07172 \t \u001b[0m \u001b[32mLR: [4.8828125e-08]  \u001b[0m\n",
            "Epoch: [38] \t \u001b[0m \u001b[34mTime: 0:00:52.303564 \t \u001b[0m \u001b[31mLoss: 0.07055 \t \u001b[0m \u001b[32mLR: [4.8828125e-08]  \u001b[0m\n",
            "Epoch: [39] \t \u001b[0m \u001b[34mTime: 0:00:52.017158 \t \u001b[0m \u001b[31mLoss: 0.07054 \t \u001b[0m \u001b[32mLR: [4.8828125e-08]  \u001b[0m\n",
            "Epoch: [40] \t \u001b[0m \u001b[34mTime: 0:00:51.693534 \t \u001b[0m \u001b[31mLoss: 0.07129 \t \u001b[0m \u001b[32mLR: [2.44140625e-08]  \u001b[0m\n",
            "Epoch: [41] \t \u001b[0m \u001b[34mTime: 0:00:51.870584 \t \u001b[0m \u001b[31mLoss: 0.07138 \t \u001b[0m \u001b[32mLR: [2.44140625e-08]  \u001b[0m\n",
            "Epoch: [42] \t \u001b[0m \u001b[34mTime: 0:00:51.351457 \t \u001b[0m \u001b[31mLoss: 0.06929 \t \u001b[0m \u001b[32mLR: [2.44140625e-08]  \u001b[0m\n",
            "Epoch: [43] \t \u001b[0m \u001b[34mTime: 0:00:51.866329 \t \u001b[0m \u001b[31mLoss: 0.07027 \t \u001b[0m \u001b[32mLR: [1.220703125e-08]  \u001b[0m\n",
            "Epoch: [44] \t \u001b[0m \u001b[34mTime: 0:00:51.441918 \t \u001b[0m \u001b[31mLoss: 0.06948 \t \u001b[0m \u001b[32mLR: [1.220703125e-08]  \u001b[0m\n",
            "Epoch: [45] \t \u001b[0m \u001b[34mTime: 0:00:51.434781 \t \u001b[0m \u001b[31mLoss: 0.0711 \t \u001b[0m \u001b[32mLR: [1.220703125e-08]  \u001b[0m\n",
            "Epoch: [46] \t \u001b[0m \u001b[34mTime: 0:00:51.097926 \t \u001b[0m \u001b[31mLoss: 0.07022 \t \u001b[0m \u001b[32mLR: [6.103515625e-09]  \u001b[0m\n",
            "Epoch: [47] \t \u001b[0m \u001b[34mTime: 0:00:51.942848 \t \u001b[0m \u001b[31mLoss: 0.07051 \t \u001b[0m \u001b[32mLR: [6.103515625e-09]  \u001b[0m\n",
            "Epoch: [48] \t \u001b[0m \u001b[34mTime: 0:00:52.154643 \t \u001b[0m \u001b[31mLoss: 0.06994 \t \u001b[0m \u001b[32mLR: [6.103515625e-09]  \u001b[0m\n",
            "Epoch: [49] \t \u001b[0m \u001b[34mTime: 0:00:51.895744 \t \u001b[0m \u001b[31mLoss: 0.07059 \t \u001b[0m \u001b[32mLR: [3.0517578125e-09]  \u001b[0m\n",
            "Epoch: [50] \t \u001b[0m \u001b[34mTime: 0:00:51.118267 \t \u001b[0m \u001b[31mLoss: 0.0704 \t \u001b[0m \u001b[32mLR: [3.0517578125e-09]  \u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir /content/output_images"
      ],
      "metadata": {
        "id": "NMPi9aVBPYHg"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from matplotlib.patches import Rectangle\n",
        "\n",
        "\n",
        "def evaluate(model, test_loader):\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        cnt = 0\n",
        "        for images, targets in test_loader:\n",
        "            images  = [img.to(device) for img in images]\n",
        "            targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n",
        "            out     = model(images)\n",
        "            scores  = out[0][\"scores\"].cpu().numpy()\n",
        "            inds    = scores > 0.7\n",
        "            boxes   = out[0][\"boxes\"].cpu().numpy()\n",
        "            bxs     = boxes[inds]\n",
        "\n",
        "            # ground Truth & image\n",
        "            gt      = targets[0][\"boxes\"].cpu().numpy()\n",
        "            image   = images[0].permute(1, 2, 0).cpu().numpy()\n",
        "            #---------------------------------------------\n",
        "            fig, ax = plt.subplots(1)\n",
        "            ax.imshow(image)\n",
        "            for j in range(len(gt)):\n",
        "                rect1 = Rectangle((int(gt[j][0]), int(gt[j][1])), \n",
        "                                   abs(gt[j][2] - gt[j][0]),\n",
        "                                   abs(gt[j][3] - gt[j][1]),\n",
        "                                   fill = False, edgecolor = (0, 1, 0), linewidth = 3)\n",
        "                ax.add_patch(rect1)\n",
        "\n",
        "            for i in range(len(bxs)):\n",
        "                rect2 = Rectangle((int(bxs[i][0]), int(bxs[i][1])),\n",
        "                                   abs(bxs[i][2] - bxs[i][0]),\n",
        "                                   abs(bxs[i][3] - bxs[i][1]),\n",
        "                                   fill = False, edgecolor = (1, 0, 0), linewidth = 3)\n",
        "                ax.add_patch(rect2)\n",
        "\n",
        "            fig.savefig(\"/content/output_images/{}.png\".format(cnt), dpi = 90, bbox_inches = \"tight\")\n",
        "            cnt += 1\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "h_d34xJCPhO9"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**plot image and box in one fig**"
      ],
      "metadata": {
        "id": "N1ZlLKsCvatr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from matplotlib.patches import Rectangle\n",
        "\n",
        "\n",
        "def evaluate(model, test_loader):\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        cnt = 0\n",
        "        fig = plt.figure(figsize = (20, 20))\n",
        "        for batch_idx ,(images, targets) in enumerate(test_loader):\n",
        "            images  = [img.to(device) for img in images]\n",
        "            targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n",
        "            out     = model(images)\n",
        "            scores  = out[0][\"scores\"].cpu().numpy()\n",
        "            inds    = scores > 0.7\n",
        "            boxes   = out[0][\"boxes\"].cpu().numpy()\n",
        "            bxs     = boxes[inds]\n",
        "\n",
        "            # ground Truth & image\n",
        "            gt      = targets[0][\"boxes\"].cpu().numpy()\n",
        "            image   = images[0].permute(1, 2, 0).cpu().numpy()\n",
        "            #---------------------------------------------\n",
        "            n_images = len(test_loader)\n",
        "            ax  = fig.add_subplot(n_images/ 4 , 11 , batch_idx + 1 )\n",
        "            ax.imshow(image)\n",
        "            for j in range(len(gt)):\n",
        "                rect1 = Rectangle((int(gt[j][0]), int(gt[j][1])), \n",
        "                                   abs(gt[j][2] - gt[j][0]),\n",
        "                                   abs(gt[j][3] - gt[j][1]),\n",
        "                                   fill = False, edgecolor = (0, 1, 0), linewidth = 3)\n",
        "                ax.add_patch(rect1)\n",
        "\n",
        "            for i in range(len(bxs)):\n",
        "                rect2 = Rectangle((int(bxs[i][0]), int(bxs[i][1])),\n",
        "                                   abs(bxs[i][2] - bxs[i][0]),\n",
        "                                   abs(bxs[i][3] - bxs[i][1]),\n",
        "                                   fill = False, edgecolor = (1, 0, 0), linewidth = 3)\n",
        "                ax.add_patch(rect2)\n",
        "\n",
        "            fig.savefig(\"/content/output_images/{}.png\".format(cnt), dpi = 90, bbox_inches = \"tight\")\n",
        "            cnt += 1\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Ypgatle1sgsx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "evaluate(model, testloader)"
      ],
      "metadata": {
        "id": "aewFn7FhUBDs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Level3- Use mobilenet backbone in FasterRCNN model**"
      ],
      "metadata": {
        "id": "nJQp5u9CvzBN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "backbone    = torchvision.models.mobilenet_v2(pretrained = True).features\n",
        "backbone.out_channels = 1280\n",
        "anchor_gen = torchvision.models.detection.rpn.AnchorGenerator(sizes = ((32, 64, 128, 256, 512), ),\n",
        "                                                      aspect_ratios = ((0.5, 1.0, 2.0), ))\n",
        "\n",
        "light_model = torchvision.models.detection.FasterRCNN(backbone = backbone, num_classes = 2,\n",
        "                                                       rpn_anchor_generator = anchor_gen)\n",
        "light_model.to(device)\n",
        "light_model"
      ],
      "metadata": {
        "id": "AmyBAe7tv1r0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class RaccoonDataset(torch.utils.data.Dataset):\n",
        "\n",
        "    def __init__(self, root, phase):\n",
        "        self.root  = root\n",
        "        self.phase = phase\n",
        "\n",
        "        #self.images_name = os.listdir(os.path.join(self.root, \"images\"))\n",
        "        self.targets     = pd.read_csv(os.path.join(self.root, \"data/{}_labels.csv\".format(self.phase)))\n",
        "        self.images_name = self.targets[\"filename\"]\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        # images\n",
        "        img_path   = os.path.join(self.root, \"images\", self.images_name[idx])\n",
        "        img        = Image.open(img_path).convert(\"RGB\")\n",
        "        img_tensor = F.to_tensor(img)\n",
        "\n",
        "        # boxes\n",
        "        target     = self.targets[self.targets[\"filename\"] == self.images_name[idx]]\n",
        "        boxes_list = target[[\"xmin\", \"ymin\", \"xmax\", \"ymax\"]].values   # boxes is a numpy array\n",
        "        boxes      = torch.tensor(boxes_list, dtype = torch.float32)\n",
        "\n",
        "        # labels\n",
        "        labels     = torch.ones((len(boxes_list), ), dtype = torch.int64)\n",
        "\n",
        "        #rac_targets = []\n",
        "        rac_target  = {}\n",
        "        rac_target[\"boxes\"]  = boxes\n",
        "        rac_target[\"labels\"] = labels\n",
        "        #rac_targets.append(rac_target)\n",
        "\n",
        "        return img_tensor, rac_target\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.images_name)\n"
      ],
      "metadata": {
        "id": "bPm-aXua4FTp"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainset = RaccoonDataset(root = \"/content/raccoon_dataset\", phase = \"train\")\n",
        "testset  = RaccoonDataset(root = \"/content/raccoon_dataset\", phase = \"test\")"
      ],
      "metadata": {
        "id": "4MrhoLI34FTr"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def new_concat(batch):\n",
        "    return tuple(zip(*batch))"
      ],
      "metadata": {
        "id": "xf1UXjX-5Bsw"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size = 2, \n",
        "                                          shuffle = True, num_workers = 2, collate_fn = new_concat)\n",
        "testloader  = torch.utils.data.DataLoader(testset,  batch_size = 1,\n",
        "                                          shuffle = True, num_workers = 2, collate_fn = new_concat)"
      ],
      "metadata": {
        "id": "iAMnDIfy4FTs"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = torch.optim.Adam(params = light_model.parameters(), lr = 0.0002, weight_decay = 5e-4)\n",
        "\n",
        "lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer = optimizer, step_size = 10, gamma = 0.5)"
      ],
      "metadata": {
        "id": "NkTPky4q4FTs"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_one_epoch(model, optimizer, train_loader):\n",
        "    model.train()\n",
        "    loss_total = 0\n",
        "    for images, targets in train_loader:\n",
        "        optimizer.zero_grad()\n",
        "        images      = [img.to(device) for img in images]\n",
        "        targets     = [{k: v.to(device) for k, v in t.items()} for t in targets]\n",
        "        loss_dict   = model(images, targets)\n",
        "        loss        = sum(loss for loss in loss_dict.values())\n",
        "        loss_total += loss\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    return loss_total / len(train_loader)\n"
      ],
      "metadata": {
        "id": "LkxFUd734FTt"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install termcolor2\n",
        "from termcolor2 import colored "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1492ac07-9453-467c-8a35-20a2c7d832ba",
        "id": "vKSQ92zd4FTt"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting termcolor2\n",
            "  Downloading termcolor2-0.0.3.tar.gz (1.6 kB)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.7/dist-packages (from termcolor2) (1.1.0)\n",
            "Building wheels for collected packages: termcolor2\n",
            "  Building wheel for termcolor2 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for termcolor2: filename=termcolor2-0.0.3-py3-none-any.whl size=1833 sha256=e89cdcea134571e6c82c2e541530ed16c6c9315d671811c18ea9b2d5a820fc90\n",
            "  Stored in directory: /root/.cache/pip/wheels/37/93/fa/3ead517c143d4381f9b4096524f21b1d86a5fa60d08210abe8\n",
            "Successfully built termcolor2\n",
            "Installing collected packages: termcolor2\n",
            "Successfully installed termcolor2-0.0.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import datetime\n",
        "train_epochs = 100\n",
        "\n",
        "for epoch in range(train_epochs):\n",
        "    s_time = datetime.datetime.now()\n",
        "    loss   = train_one_epoch(light_model, optimizer, trainloader)\n",
        "    e_time = datetime.datetime.now()\n",
        "    train_time = str(e_time - s_time)\n",
        "    print(colored(\"Epoch: [{}] \\t \".format(epoch + 1)),\n",
        "          colored(f\"Time: {train_time} \\t \", color = \"blue\"),\n",
        "          colored(\"Loss: {0:.4} \\t \".format(loss), color = \"red\"),\n",
        "          colored(\"LR: {}  \".format(lr_scheduler.get_last_lr()), color = \"green\")) \n",
        "\n",
        "\n",
        "    lr_scheduler.step()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d41832b1-a39e-49ca-f4a6-69efcc9d1998",
        "id": "XWCFHLMj4FTv"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: [1] \t \u001b[0m \u001b[34mTime: 0:00:32.612377 \t \u001b[0m \u001b[31mLoss: 0.4779 \t \u001b[0m \u001b[32mLR: [0.0002]  \u001b[0m\n",
            "Epoch: [2] \t \u001b[0m \u001b[34mTime: 0:00:32.714098 \t \u001b[0m \u001b[31mLoss: 0.3307 \t \u001b[0m \u001b[32mLR: [0.0002]  \u001b[0m\n",
            "Epoch: [3] \t \u001b[0m \u001b[34mTime: 0:00:32.722975 \t \u001b[0m \u001b[31mLoss: 0.2577 \t \u001b[0m \u001b[32mLR: [0.0002]  \u001b[0m\n",
            "Epoch: [4] \t \u001b[0m \u001b[34mTime: 0:00:33.765360 \t \u001b[0m \u001b[31mLoss: 0.2303 \t \u001b[0m \u001b[32mLR: [0.0002]  \u001b[0m\n",
            "Epoch: [5] \t \u001b[0m \u001b[34mTime: 0:00:34.092729 \t \u001b[0m \u001b[31mLoss: 0.222 \t \u001b[0m \u001b[32mLR: [0.0002]  \u001b[0m\n",
            "Epoch: [6] \t \u001b[0m \u001b[34mTime: 0:00:34.298914 \t \u001b[0m \u001b[31mLoss: 0.1834 \t \u001b[0m \u001b[32mLR: [0.0002]  \u001b[0m\n",
            "Epoch: [7] \t \u001b[0m \u001b[34mTime: 0:00:34.250955 \t \u001b[0m \u001b[31mLoss: 0.166 \t \u001b[0m \u001b[32mLR: [0.0002]  \u001b[0m\n",
            "Epoch: [8] \t \u001b[0m \u001b[34mTime: 0:00:34.574542 \t \u001b[0m \u001b[31mLoss: 0.1543 \t \u001b[0m \u001b[32mLR: [0.0002]  \u001b[0m\n",
            "Epoch: [9] \t \u001b[0m \u001b[34mTime: 0:00:34.333593 \t \u001b[0m \u001b[31mLoss: 0.1808 \t \u001b[0m \u001b[32mLR: [0.0002]  \u001b[0m\n",
            "Epoch: [10] \t \u001b[0m \u001b[34mTime: 0:00:34.306782 \t \u001b[0m \u001b[31mLoss: 0.1482 \t \u001b[0m \u001b[32mLR: [0.0002]  \u001b[0m\n",
            "Epoch: [11] \t \u001b[0m \u001b[34mTime: 0:00:34.509424 \t \u001b[0m \u001b[31mLoss: 0.1221 \t \u001b[0m \u001b[32mLR: [0.0001]  \u001b[0m\n",
            "Epoch: [12] \t \u001b[0m \u001b[34mTime: 0:00:34.337437 \t \u001b[0m \u001b[31mLoss: 0.1093 \t \u001b[0m \u001b[32mLR: [0.0001]  \u001b[0m\n",
            "Epoch: [13] \t \u001b[0m \u001b[34mTime: 0:00:34.943607 \t \u001b[0m \u001b[31mLoss: 0.09688 \t \u001b[0m \u001b[32mLR: [0.0001]  \u001b[0m\n",
            "Epoch: [14] \t \u001b[0m \u001b[34mTime: 0:00:34.580905 \t \u001b[0m \u001b[31mLoss: 0.09904 \t \u001b[0m \u001b[32mLR: [0.0001]  \u001b[0m\n",
            "Epoch: [15] \t \u001b[0m \u001b[34mTime: 0:00:34.754986 \t \u001b[0m \u001b[31mLoss: 0.08929 \t \u001b[0m \u001b[32mLR: [0.0001]  \u001b[0m\n",
            "Epoch: [16] \t \u001b[0m \u001b[34mTime: 0:00:34.919728 \t \u001b[0m \u001b[31mLoss: 0.08495 \t \u001b[0m \u001b[32mLR: [0.0001]  \u001b[0m\n",
            "Epoch: [17] \t \u001b[0m \u001b[34mTime: 0:00:34.936524 \t \u001b[0m \u001b[31mLoss: 0.08483 \t \u001b[0m \u001b[32mLR: [0.0001]  \u001b[0m\n",
            "Epoch: [18] \t \u001b[0m \u001b[34mTime: 0:00:34.764005 \t \u001b[0m \u001b[31mLoss: 0.08444 \t \u001b[0m \u001b[32mLR: [0.0001]  \u001b[0m\n",
            "Epoch: [19] \t \u001b[0m \u001b[34mTime: 0:00:34.773614 \t \u001b[0m \u001b[31mLoss: 0.08619 \t \u001b[0m \u001b[32mLR: [0.0001]  \u001b[0m\n",
            "Epoch: [20] \t \u001b[0m \u001b[34mTime: 0:00:34.474022 \t \u001b[0m \u001b[31mLoss: 0.08035 \t \u001b[0m \u001b[32mLR: [0.0001]  \u001b[0m\n",
            "Epoch: [21] \t \u001b[0m \u001b[34mTime: 0:00:34.671645 \t \u001b[0m \u001b[31mLoss: 0.06397 \t \u001b[0m \u001b[32mLR: [5e-05]  \u001b[0m\n",
            "Epoch: [22] \t \u001b[0m \u001b[34mTime: 0:00:34.741817 \t \u001b[0m \u001b[31mLoss: 0.05733 \t \u001b[0m \u001b[32mLR: [5e-05]  \u001b[0m\n",
            "Epoch: [23] \t \u001b[0m \u001b[34mTime: 0:00:34.813206 \t \u001b[0m \u001b[31mLoss: 0.05353 \t \u001b[0m \u001b[32mLR: [5e-05]  \u001b[0m\n",
            "Epoch: [24] \t \u001b[0m \u001b[34mTime: 0:00:34.659067 \t \u001b[0m \u001b[31mLoss: 0.05436 \t \u001b[0m \u001b[32mLR: [5e-05]  \u001b[0m\n",
            "Epoch: [25] \t \u001b[0m \u001b[34mTime: 0:00:34.647794 \t \u001b[0m \u001b[31mLoss: 0.05104 \t \u001b[0m \u001b[32mLR: [5e-05]  \u001b[0m\n",
            "Epoch: [26] \t \u001b[0m \u001b[34mTime: 0:00:35.050739 \t \u001b[0m \u001b[31mLoss: 0.04781 \t \u001b[0m \u001b[32mLR: [5e-05]  \u001b[0m\n",
            "Epoch: [27] \t \u001b[0m \u001b[34mTime: 0:00:34.882452 \t \u001b[0m \u001b[31mLoss: 0.04756 \t \u001b[0m \u001b[32mLR: [5e-05]  \u001b[0m\n",
            "Epoch: [28] \t \u001b[0m \u001b[34mTime: 0:00:34.830215 \t \u001b[0m \u001b[31mLoss: 0.04516 \t \u001b[0m \u001b[32mLR: [5e-05]  \u001b[0m\n",
            "Epoch: [29] \t \u001b[0m \u001b[34mTime: 0:00:34.701794 \t \u001b[0m \u001b[31mLoss: 0.04616 \t \u001b[0m \u001b[32mLR: [5e-05]  \u001b[0m\n",
            "Epoch: [30] \t \u001b[0m \u001b[34mTime: 0:00:34.934273 \t \u001b[0m \u001b[31mLoss: 0.04823 \t \u001b[0m \u001b[32mLR: [5e-05]  \u001b[0m\n",
            "Epoch: [31] \t \u001b[0m \u001b[34mTime: 0:00:34.703307 \t \u001b[0m \u001b[31mLoss: 0.03997 \t \u001b[0m \u001b[32mLR: [2.5e-05]  \u001b[0m\n",
            "Epoch: [32] \t \u001b[0m \u001b[34mTime: 0:00:34.874088 \t \u001b[0m \u001b[31mLoss: 0.03687 \t \u001b[0m \u001b[32mLR: [2.5e-05]  \u001b[0m\n",
            "Epoch: [33] \t \u001b[0m \u001b[34mTime: 0:00:35.185357 \t \u001b[0m \u001b[31mLoss: 0.0341 \t \u001b[0m \u001b[32mLR: [2.5e-05]  \u001b[0m\n",
            "Epoch: [34] \t \u001b[0m \u001b[34mTime: 0:00:34.762272 \t \u001b[0m \u001b[31mLoss: 0.03369 \t \u001b[0m \u001b[32mLR: [2.5e-05]  \u001b[0m\n",
            "Epoch: [35] \t \u001b[0m \u001b[34mTime: 0:00:34.915072 \t \u001b[0m \u001b[31mLoss: 0.03407 \t \u001b[0m \u001b[32mLR: [2.5e-05]  \u001b[0m\n",
            "Epoch: [36] \t \u001b[0m \u001b[34mTime: 0:00:34.920282 \t \u001b[0m \u001b[31mLoss: 0.03354 \t \u001b[0m \u001b[32mLR: [2.5e-05]  \u001b[0m\n",
            "Epoch: [37] \t \u001b[0m \u001b[34mTime: 0:00:35.025834 \t \u001b[0m \u001b[31mLoss: 0.0318 \t \u001b[0m \u001b[32mLR: [2.5e-05]  \u001b[0m\n",
            "Epoch: [38] \t \u001b[0m \u001b[34mTime: 0:00:34.993332 \t \u001b[0m \u001b[31mLoss: 0.03131 \t \u001b[0m \u001b[32mLR: [2.5e-05]  \u001b[0m\n",
            "Epoch: [39] \t \u001b[0m \u001b[34mTime: 0:00:35.165892 \t \u001b[0m \u001b[31mLoss: 0.03296 \t \u001b[0m \u001b[32mLR: [2.5e-05]  \u001b[0m\n",
            "Epoch: [40] \t \u001b[0m \u001b[34mTime: 0:00:34.784018 \t \u001b[0m \u001b[31mLoss: 0.03366 \t \u001b[0m \u001b[32mLR: [2.5e-05]  \u001b[0m\n",
            "Epoch: [41] \t \u001b[0m \u001b[34mTime: 0:00:35.025477 \t \u001b[0m \u001b[31mLoss: 0.03087 \t \u001b[0m \u001b[32mLR: [1.25e-05]  \u001b[0m\n",
            "Epoch: [42] \t \u001b[0m \u001b[34mTime: 0:00:34.925292 \t \u001b[0m \u001b[31mLoss: 0.02847 \t \u001b[0m \u001b[32mLR: [1.25e-05]  \u001b[0m\n",
            "Epoch: [43] \t \u001b[0m \u001b[34mTime: 0:00:34.997837 \t \u001b[0m \u001b[31mLoss: 0.02803 \t \u001b[0m \u001b[32mLR: [1.25e-05]  \u001b[0m\n",
            "Epoch: [44] \t \u001b[0m \u001b[34mTime: 0:00:35.277343 \t \u001b[0m \u001b[31mLoss: 0.02548 \t \u001b[0m \u001b[32mLR: [1.25e-05]  \u001b[0m\n",
            "Epoch: [45] \t \u001b[0m \u001b[34mTime: 0:00:34.820796 \t \u001b[0m \u001b[31mLoss: 0.02719 \t \u001b[0m \u001b[32mLR: [1.25e-05]  \u001b[0m\n",
            "Epoch: [46] \t \u001b[0m \u001b[34mTime: 0:00:34.823370 \t \u001b[0m \u001b[31mLoss: 0.02646 \t \u001b[0m \u001b[32mLR: [1.25e-05]  \u001b[0m\n",
            "Epoch: [47] \t \u001b[0m \u001b[34mTime: 0:00:35.007454 \t \u001b[0m \u001b[31mLoss: 0.02577 \t \u001b[0m \u001b[32mLR: [1.25e-05]  \u001b[0m\n",
            "Epoch: [48] \t \u001b[0m \u001b[34mTime: 0:00:35.027966 \t \u001b[0m \u001b[31mLoss: 0.02584 \t \u001b[0m \u001b[32mLR: [1.25e-05]  \u001b[0m\n",
            "Epoch: [49] \t \u001b[0m \u001b[34mTime: 0:00:34.904774 \t \u001b[0m \u001b[31mLoss: 0.02572 \t \u001b[0m \u001b[32mLR: [1.25e-05]  \u001b[0m\n",
            "Epoch: [50] \t \u001b[0m \u001b[34mTime: 0:00:34.970407 \t \u001b[0m \u001b[31mLoss: 0.02636 \t \u001b[0m \u001b[32mLR: [1.25e-05]  \u001b[0m\n",
            "Epoch: [51] \t \u001b[0m \u001b[34mTime: 0:00:35.188859 \t \u001b[0m \u001b[31mLoss: 0.02382 \t \u001b[0m \u001b[32mLR: [6.25e-06]  \u001b[0m\n",
            "Epoch: [52] \t \u001b[0m \u001b[34mTime: 0:00:35.047737 \t \u001b[0m \u001b[31mLoss: 0.02303 \t \u001b[0m \u001b[32mLR: [6.25e-06]  \u001b[0m\n",
            "Epoch: [53] \t \u001b[0m \u001b[34mTime: 0:00:35.197705 \t \u001b[0m \u001b[31mLoss: 0.02304 \t \u001b[0m \u001b[32mLR: [6.25e-06]  \u001b[0m\n",
            "Epoch: [54] \t \u001b[0m \u001b[34mTime: 0:00:34.871667 \t \u001b[0m \u001b[31mLoss: 0.02273 \t \u001b[0m \u001b[32mLR: [6.25e-06]  \u001b[0m\n",
            "Epoch: [55] \t \u001b[0m \u001b[34mTime: 0:00:35.178481 \t \u001b[0m \u001b[31mLoss: 0.02195 \t \u001b[0m \u001b[32mLR: [6.25e-06]  \u001b[0m\n",
            "Epoch: [56] \t \u001b[0m \u001b[34mTime: 0:00:35.106028 \t \u001b[0m \u001b[31mLoss: 0.02327 \t \u001b[0m \u001b[32mLR: [6.25e-06]  \u001b[0m\n",
            "Epoch: [57] \t \u001b[0m \u001b[34mTime: 0:00:35.279515 \t \u001b[0m \u001b[31mLoss: 0.02223 \t \u001b[0m \u001b[32mLR: [6.25e-06]  \u001b[0m\n",
            "Epoch: [58] \t \u001b[0m \u001b[34mTime: 0:00:35.175661 \t \u001b[0m \u001b[31mLoss: 0.02168 \t \u001b[0m \u001b[32mLR: [6.25e-06]  \u001b[0m\n",
            "Epoch: [59] \t \u001b[0m \u001b[34mTime: 0:00:34.968297 \t \u001b[0m \u001b[31mLoss: 0.02158 \t \u001b[0m \u001b[32mLR: [6.25e-06]  \u001b[0m\n",
            "Epoch: [60] \t \u001b[0m \u001b[34mTime: 0:00:35.317007 \t \u001b[0m \u001b[31mLoss: 0.02156 \t \u001b[0m \u001b[32mLR: [6.25e-06]  \u001b[0m\n",
            "Epoch: [61] \t \u001b[0m \u001b[34mTime: 0:00:35.048848 \t \u001b[0m \u001b[31mLoss: 0.01993 \t \u001b[0m \u001b[32mLR: [3.125e-06]  \u001b[0m\n",
            "Epoch: [62] \t \u001b[0m \u001b[34mTime: 0:00:35.146893 \t \u001b[0m \u001b[31mLoss: 0.02062 \t \u001b[0m \u001b[32mLR: [3.125e-06]  \u001b[0m\n",
            "Epoch: [63] \t \u001b[0m \u001b[34mTime: 0:00:34.953725 \t \u001b[0m \u001b[31mLoss: 0.02062 \t \u001b[0m \u001b[32mLR: [3.125e-06]  \u001b[0m\n",
            "Epoch: [64] \t \u001b[0m \u001b[34mTime: 0:00:34.937030 \t \u001b[0m \u001b[31mLoss: 0.02053 \t \u001b[0m \u001b[32mLR: [3.125e-06]  \u001b[0m\n",
            "Epoch: [65] \t \u001b[0m \u001b[34mTime: 0:00:35.268328 \t \u001b[0m \u001b[31mLoss: 0.01998 \t \u001b[0m \u001b[32mLR: [3.125e-06]  \u001b[0m\n",
            "Epoch: [66] \t \u001b[0m \u001b[34mTime: 0:00:35.037118 \t \u001b[0m \u001b[31mLoss: 0.01987 \t \u001b[0m \u001b[32mLR: [3.125e-06]  \u001b[0m\n",
            "Epoch: [67] \t \u001b[0m \u001b[34mTime: 0:00:34.906016 \t \u001b[0m \u001b[31mLoss: 0.02031 \t \u001b[0m \u001b[32mLR: [3.125e-06]  \u001b[0m\n",
            "Epoch: [68] \t \u001b[0m \u001b[34mTime: 0:00:35.132605 \t \u001b[0m \u001b[31mLoss: 0.01987 \t \u001b[0m \u001b[32mLR: [3.125e-06]  \u001b[0m\n",
            "Epoch: [69] \t \u001b[0m \u001b[34mTime: 0:00:35.270597 \t \u001b[0m \u001b[31mLoss: 0.01999 \t \u001b[0m \u001b[32mLR: [3.125e-06]  \u001b[0m\n",
            "Epoch: [70] \t \u001b[0m \u001b[34mTime: 0:00:35.254851 \t \u001b[0m \u001b[31mLoss: 0.01999 \t \u001b[0m \u001b[32mLR: [3.125e-06]  \u001b[0m\n",
            "Epoch: [71] \t \u001b[0m \u001b[34mTime: 0:00:35.267051 \t \u001b[0m \u001b[31mLoss: 0.02034 \t \u001b[0m \u001b[32mLR: [1.5625e-06]  \u001b[0m\n",
            "Epoch: [72] \t \u001b[0m \u001b[34mTime: 0:00:35.190857 \t \u001b[0m \u001b[31mLoss: 0.01888 \t \u001b[0m \u001b[32mLR: [1.5625e-06]  \u001b[0m\n",
            "Epoch: [73] \t \u001b[0m \u001b[34mTime: 0:00:35.184334 \t \u001b[0m \u001b[31mLoss: 0.0197 \t \u001b[0m \u001b[32mLR: [1.5625e-06]  \u001b[0m\n",
            "Epoch: [74] \t \u001b[0m \u001b[34mTime: 0:00:35.131147 \t \u001b[0m \u001b[31mLoss: 0.01999 \t \u001b[0m \u001b[32mLR: [1.5625e-06]  \u001b[0m\n",
            "Epoch: [75] \t \u001b[0m \u001b[34mTime: 0:00:35.307450 \t \u001b[0m \u001b[31mLoss: 0.01905 \t \u001b[0m \u001b[32mLR: [1.5625e-06]  \u001b[0m\n",
            "Epoch: [76] \t \u001b[0m \u001b[34mTime: 0:00:35.096494 \t \u001b[0m \u001b[31mLoss: 0.01894 \t \u001b[0m \u001b[32mLR: [1.5625e-06]  \u001b[0m\n",
            "Epoch: [77] \t \u001b[0m \u001b[34mTime: 0:00:35.038119 \t \u001b[0m \u001b[31mLoss: 0.0188 \t \u001b[0m \u001b[32mLR: [1.5625e-06]  \u001b[0m\n",
            "Epoch: [78] \t \u001b[0m \u001b[34mTime: 0:00:35.216236 \t \u001b[0m \u001b[31mLoss: 0.01882 \t \u001b[0m \u001b[32mLR: [1.5625e-06]  \u001b[0m\n",
            "Epoch: [79] \t \u001b[0m \u001b[34mTime: 0:00:35.356823 \t \u001b[0m \u001b[31mLoss: 0.01907 \t \u001b[0m \u001b[32mLR: [1.5625e-06]  \u001b[0m\n",
            "Epoch: [80] \t \u001b[0m \u001b[34mTime: 0:00:34.965744 \t \u001b[0m \u001b[31mLoss: 0.01897 \t \u001b[0m \u001b[32mLR: [1.5625e-06]  \u001b[0m\n",
            "Epoch: [81] \t \u001b[0m \u001b[34mTime: 0:00:35.069340 \t \u001b[0m \u001b[31mLoss: 0.01941 \t \u001b[0m \u001b[32mLR: [7.8125e-07]  \u001b[0m\n",
            "Epoch: [82] \t \u001b[0m \u001b[34mTime: 0:00:34.903255 \t \u001b[0m \u001b[31mLoss: 0.01799 \t \u001b[0m \u001b[32mLR: [7.8125e-07]  \u001b[0m\n",
            "Epoch: [83] \t \u001b[0m \u001b[34mTime: 0:00:35.199476 \t \u001b[0m \u001b[31mLoss: 0.01905 \t \u001b[0m \u001b[32mLR: [7.8125e-07]  \u001b[0m\n",
            "Epoch: [84] \t \u001b[0m \u001b[34mTime: 0:00:35.243037 \t \u001b[0m \u001b[31mLoss: 0.01949 \t \u001b[0m \u001b[32mLR: [7.8125e-07]  \u001b[0m\n",
            "Epoch: [85] \t \u001b[0m \u001b[34mTime: 0:00:35.137652 \t \u001b[0m \u001b[31mLoss: 0.01855 \t \u001b[0m \u001b[32mLR: [7.8125e-07]  \u001b[0m\n",
            "Epoch: [86] \t \u001b[0m \u001b[34mTime: 0:00:35.131146 \t \u001b[0m \u001b[31mLoss: 0.01893 \t \u001b[0m \u001b[32mLR: [7.8125e-07]  \u001b[0m\n",
            "Epoch: [87] \t \u001b[0m \u001b[34mTime: 0:00:35.124992 \t \u001b[0m \u001b[31mLoss: 0.01882 \t \u001b[0m \u001b[32mLR: [7.8125e-07]  \u001b[0m\n",
            "Epoch: [88] \t \u001b[0m \u001b[34mTime: 0:00:35.018410 \t \u001b[0m \u001b[31mLoss: 0.01871 \t \u001b[0m \u001b[32mLR: [7.8125e-07]  \u001b[0m\n",
            "Epoch: [89] \t \u001b[0m \u001b[34mTime: 0:00:35.273763 \t \u001b[0m \u001b[31mLoss: 0.01797 \t \u001b[0m \u001b[32mLR: [7.8125e-07]  \u001b[0m\n",
            "Epoch: [90] \t \u001b[0m \u001b[34mTime: 0:00:35.298804 \t \u001b[0m \u001b[31mLoss: 0.01821 \t \u001b[0m \u001b[32mLR: [7.8125e-07]  \u001b[0m\n",
            "Epoch: [91] \t \u001b[0m \u001b[34mTime: 0:00:35.443854 \t \u001b[0m \u001b[31mLoss: 0.01809 \t \u001b[0m \u001b[32mLR: [3.90625e-07]  \u001b[0m\n",
            "Epoch: [92] \t \u001b[0m \u001b[34mTime: 0:00:35.309307 \t \u001b[0m \u001b[31mLoss: 0.01803 \t \u001b[0m \u001b[32mLR: [3.90625e-07]  \u001b[0m\n",
            "Epoch: [93] \t \u001b[0m \u001b[34mTime: 0:00:35.319835 \t \u001b[0m \u001b[31mLoss: 0.01878 \t \u001b[0m \u001b[32mLR: [3.90625e-07]  \u001b[0m\n",
            "Epoch: [94] \t \u001b[0m \u001b[34mTime: 0:00:35.236723 \t \u001b[0m \u001b[31mLoss: 0.01754 \t \u001b[0m \u001b[32mLR: [3.90625e-07]  \u001b[0m\n",
            "Epoch: [95] \t \u001b[0m \u001b[34mTime: 0:00:35.230075 \t \u001b[0m \u001b[31mLoss: 0.01785 \t \u001b[0m \u001b[32mLR: [3.90625e-07]  \u001b[0m\n",
            "Epoch: [96] \t \u001b[0m \u001b[34mTime: 0:00:35.362576 \t \u001b[0m \u001b[31mLoss: 0.01851 \t \u001b[0m \u001b[32mLR: [3.90625e-07]  \u001b[0m\n",
            "Epoch: [97] \t \u001b[0m \u001b[34mTime: 0:00:35.217621 \t \u001b[0m \u001b[31mLoss: 0.01896 \t \u001b[0m \u001b[32mLR: [3.90625e-07]  \u001b[0m\n",
            "Epoch: [98] \t \u001b[0m \u001b[34mTime: 0:00:35.268419 \t \u001b[0m \u001b[31mLoss: 0.01797 \t \u001b[0m \u001b[32mLR: [3.90625e-07]  \u001b[0m\n",
            "Epoch: [99] \t \u001b[0m \u001b[34mTime: 0:00:35.296971 \t \u001b[0m \u001b[31mLoss: 0.01915 \t \u001b[0m \u001b[32mLR: [3.90625e-07]  \u001b[0m\n",
            "Epoch: [100] \t \u001b[0m \u001b[34mTime: 0:00:35.122676 \t \u001b[0m \u001b[31mLoss: 0.01799 \t \u001b[0m \u001b[32mLR: [3.90625e-07]  \u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir /content/MobileNet"
      ],
      "metadata": {
        "id": "Tllcdk8j4jPT"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "light_model.eval()\n",
        "with torch.no_grad():\n",
        "    cnt = 0\n",
        "    for images, targets in testloader:\n",
        "        images  = [img.to(device) for img in images]\n",
        "        targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n",
        "        out     = light_model(images)"
      ],
      "metadata": {
        "id": "yp1AkIuWDCH5"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "out"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WWP4yodEDHz0",
        "outputId": "0bf9529c-c681-4895-a393-79efe836cb33"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'boxes': tensor([[ 23.4636,   2.3790, 474.8974, 484.1474]], device='cuda:0'),\n",
              "  'labels': tensor([1], device='cuda:0'),\n",
              "  'scores': tensor([0.9997], device='cuda:0')}]"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from matplotlib.patches import Rectangle\n",
        "\n",
        "\n",
        "def evaluate(model, test_loader):\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        cnt = 0\n",
        "        for images, targets in test_loader:\n",
        "            images  = [img.to(device) for img in images]\n",
        "            targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n",
        "            out     = model(images)\n",
        "            scores  = out[0][\"scores\"].cpu().numpy()\n",
        "            inds    = scores > 0.7\n",
        "            boxes   = out[0][\"boxes\"].cpu().numpy()\n",
        "            bxs     = boxes[inds]\n",
        "\n",
        "            # ground Truth & image\n",
        "            gt      = targets[0][\"boxes\"].cpu().numpy()\n",
        "            image   = images[0].permute(1, 2, 0).cpu().numpy()\n",
        "            #---------------------------------------------\n",
        "            fig, ax = plt.subplots(1)\n",
        "            ax.imshow(image)\n",
        "            for j in range(len(gt)):\n",
        "                rect1 = Rectangle((int(gt[j][0]), int(gt[j][1])), \n",
        "                                   abs(gt[j][2] - gt[j][0]),\n",
        "                                   abs(gt[j][3] - gt[j][1]),\n",
        "                                   fill = False, edgecolor = (0, 1, 0), linewidth = 3)\n",
        "                ax.add_patch(rect1)\n",
        "\n",
        "            for i in range(len(bxs)):\n",
        "                rect2 = Rectangle((int(bxs[i][0]), int(bxs[i][1])),\n",
        "                                   abs(bxs[i][2] - bxs[i][0]),\n",
        "                                   abs(bxs[i][3] - bxs[i][1]),\n",
        "                                   fill = False, edgecolor = (1, 0, 0), linewidth = 3)\n",
        "                ax.add_patch(rect2)\n",
        "\n",
        "            fig.savefig(\"/content/MobileNet/{}.png\".format(cnt), dpi = 90, bbox_inches = \"tight\")\n",
        "            cnt += 1\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "zg2T2UDo4jPU"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "evaluate(light_model, testloader)"
      ],
      "metadata": {
        "id": "EZsfA7bN4rcw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## change the anchorgenerator class"
      ],
      "metadata": {
        "id": "W9M_DWgx7sTn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "backbone = torchvision.models.mobilenet_v2(pretrained = True).features\n",
        "backbone.out_channels = 1280\n",
        "\n",
        "anchor_gen = torchvision.models.detection.rpn.AnchorGenerator(sizes = ((32, 64, 128, 256, 512), ),\n",
        "                                                      aspect_ratios = ((0.5, 1.0, 2.0), ))\n",
        "\n",
        "light_model2 = torchvision.models.detection.FasterRCNN(backbone = backbone, num_classes = 2,\n",
        "                                                       rpn_anchor_generator = anchor_gen)\n",
        "\n",
        "light_model2.to(device)\n",
        "light_model2.train()\n",
        "light_model2"
      ],
      "metadata": {
        "id": "wHEjUp_27xbq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.tensor([1, 2, 3, 4])\n",
        "print(x.size())\n",
        "y = torch.unsqueeze(x, 0)\n",
        "print(y.size())\n",
        "z = torch.unsqueeze(x, 1)\n",
        "print(z.size())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NrXBjAqwDvXx",
        "outputId": "145b6bb1-6732-4e7b-d7d6-8871f4530d9b"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([4])\n",
            "torch.Size([1, 4])\n",
            "torch.Size([4, 1])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git push https://github.com/HoseinEsk1994/FasterRCNN_resnet50_mobilenetv2.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l-O3vschd_ja",
        "outputId": "d8c38c3c-4dd9-4314-fcb9-c00e36c1e8e0"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: not a git repository (or any of the parent directories): .git\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "XRk2jlnJeUTT"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}